By default, Terraform looks for terraform.tfvars (or *.auto.tfvars) to load variable values.
✅ If you don't create terraform.tfvars:
    Terraform will not automatically assign values to your variables
    it wait to have the values during runtime
✅ If you create a file with a different name (e.g. dev.tfvars):
    Terraform will not use it automatically.
    To use it, you must pass it explicitly:
    terraform apply -var-file="dev.tfvars"

--------------------------------------------------------------------------------------------
✅ Using dev.tfvars and prod.tfvars Safely
If you're using multiple .tfvars files like dev.tfvars and prod.tfvars, you must avoid state file conflicts.
Problem: If your backend config uses: key = "terraform.tfstate"
Then all environments (dev, prod, etc.) will use the same state file, which can cause one to override the other

Solution 1: Dynamic Backend Key
Change the backend key to use a variable: key = "${var.env}.tfstate"
Then apply like this: terraform apply -var-file="dev.tfvars", terraform apply -var-file="prod.tfvars"
❗Note: Backend config is processed before your variables and code, so var.env doesn't work directly in backend blocks.

Solution 2: Use Terraform Workspaces (Recommended)
Terraform handles this cleanly using workspaces, which separate state files automatically.
✔️ How to Use:
List workspaces: terraform workspace list >> Default: you'll see default
Create a new workspace:
    terraform workspace new prod
    terraform workspace new dev
Switch between them:
    terraform workspace select dev
    terraform apply -var-file="dev.tfvars"
    terraform workspace select prod
    terraform apply -var-file="prod.tfvars"
✅ Result: Terraform stores state files like:
    s3://your-bucket-name/env:/dev/terraform.tfstate
    s3://your-bucket-name/env:/prod/terraform.tfstate
"env:/  prod/ >> folder for your workspace include separated terraform.tfstate
    you handle the problem without edit the backend file"
--------------------------------------------------------------------------------------
count = 2 >> 
If you already have an EC2 instance created in Terraform and you change its configuration to use count = 2,
then run terraform apply, here's exactly what happens:
    Terraform destroys the old single EC2 instance.
    Then it creates 2 new EC2 instances.
Why? Because resources without count and with count are treated differently in Terraform's state.
So, Terraform treats it as:
    The original instance no longer exists.
    Two new instances are needed (aws_instance.web[0] and aws_instance.web[1]).
🛑 Important Warning:
    Any data on the old EC2 instance will be lost (unless you take measures like using an EBS volume).
    This is not an in-place update, it's a destroy and recreate operation.
--------------------------------------------------------------------------------------
You can use "count" as a trick to create some resources in workspace and don't create them in other
define variable, assign its value in each prod.tfvars, dev.tfvars
--------------------------------------------------------------------------------------
in outputs.tf:
-- option sensitive = true make the output not printed(used in sensitive data)
-- since you define output you can retrieve its value:
    terraform output vpc_id 
output.tf is not just for printing. It's a powerful way to expose data from Terraform to other 
tools, especially Ansible, scripts, or CI/CD pipelines
You can use output.tf to collect EC2 instance IPs and create an inventory file for Ansible automatically
-- Important in modules
--------------------------------------------------------------------------------------
provisioners
•Provisioners can be used to model specific actions on the local machine or on a 
remote machine in order to prepare servers or other infrastructure objects for 
service.  only run after first creation of resource
-- you can put it inside the resource
    provisioner "local-exec" {
        command = "echo The server's IP address is ${self.private_ip}"
    }
-- outside in null resource (you may need terraform init :)
# just for test
# resource null_resource run {
#   provisioner "local-exec" {
#     command = "mkdir test"
#   }
#   depends_on = [aws_instance.Bastion,aws_instance.application]
# }

When using null_resource with provisioner blocks 
(like local-exec or remote-exec),
Terraform only runs the provisioner the first time, unless the resource changes.
To force it to run again:
    terraform taint null_resource.run
    terraform apply
This marks the null_resource.run as tainted,
so Terraform will destroy and recreate it, which re-triggers the provisioner.

Remove the taint (undo it): terraform untaint null_resource.run
This is useful if you tainted it by mistake and don’t want it to re-run on the next apply.
--------------------------------------------------------------------------------------
Terraform data resources are used to reference existing resources that are not managed by your 
code, so you can read and use their attributes without managing or modifying them.
Example: Using data to Reference an Existing VPC
✅ Benefit
    Read-only access to resources (no risk of changing/deleting them)
    Useful for shared infrastructure
    Keeps modules reusable and safe